{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Assignment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the `REC0111.sav`, `RE223132.sav` and `RE516171.sav` files and their variables and values labels from this path `\"../../_data/endes/2019\"`. The name of imported files should be named as `rec_1`, `rec_2` and `rec_3` for files `REC0111.sav`, `RE223132.sav` and `RE516171.sav` respectively. The name of the variable and value labels should be `var_labels1` and `value_labels1` for `rec1`, `var_labels2` and `value_labels2` for `rec2`, and `var_labels3` and `value_labels3` for `rec3`. **Hint: See the section 3.3.4 of [the lecture 3](https://github.com/alexanderquispe/Diplomado_PUCP/blob/main/Lecture_3/Lecture_3.ipynb)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# First, we import the three datasets from the given path\n",
    "rec_1 = pd.read_spss(r\"../../_data/endes/2019/REC0111.sav\")\n",
    "rec_2 = pd.read_spss(r\"../../_data/endes/2019/RE223132.sav\")\n",
    "rec_3 = pd.read_spss(r\"../../_data/endes/2019/RE516171.sav\")\n",
    "\n",
    "# Now, in order to get the labels, we can use savReaderWriter for each of the three datasets:\n",
    "import savReaderWriter as sav\n",
    "with sav.SavHeaderReader( r\"../../_data/endes/2019/REC0111.sav\", ioUtf8=True) as header:\n",
    "    metadata = header.all()\n",
    "    var_labels1 = metadata.varLabels\n",
    "    value_labels1 = metadata.valueLabels\n",
    "\n",
    "rec_1.attrs[ 'value_labels' ] = value_labels1\n",
    "rec_1.attrs[ 'var_labels' ] = var_labels1\n",
    "\n",
    "with sav.SavHeaderReader( r\"../../_data/endes/2019/RE223132.sav\", ioUtf8=True) as header:\n",
    "    metadata = header.all()\n",
    "    var_labels2 = metadata.varLabels\n",
    "    value_labels2 = metadata.valueLabels\n",
    "\n",
    "rec_2.attrs[ 'value_labels' ] = value_labels2\n",
    "rec_2.attrs[ 'var_labels' ] = var_labels2\n",
    "\n",
    "with sav.SavHeaderReader( r\"../../_data/endes/2019/RE516171.sav\", ioUtf8=True) as header:\n",
    "    metadata = header.all()\n",
    "    var_labels3 = metadata.varLabels\n",
    "    value_labels3 = metadata.valueLabels\n",
    "\n",
    "rec_3.attrs[ 'value_labels' ] = value_labels3\n",
    "rec_3.attrs[ 'var_labels' ] = var_labels3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Select the following columns for each data set:\n",
    "|Data|Columns|\n",
    "|---|---|\n",
    "|rec1| CASEID, V000, V001, V002, V003, V004, V007, V008, V009, V010, V011, V012, V024, V102, V120, V121, V122, V123, V124, V125, V127, V133 |\n",
    "|rec2| CASEID, V201, V218, V301, V302, V323, V323A, V325A, V326, V327, V337, V359, V360, V361, V362, V363, V364, V367, V372, V372A, V375A, V376, V376A, V379, V380 |\n",
    "|rec3| CASEID, V501, V502, V503, V504, V505, V506, V507, V508, V509, V510, V511, V512, V513, V525, V613, V714, V715 |\n",
    "\n",
    "\n",
    "Additionally, you should update the variables and value labels objects. They must have information only for the selected columns. The new dataframes should be name as `rec1_1`, `rec2_1`, and `rec3_1`. The new varible labels objects should be named as `new_var_labels1`, `new_var_labels2`, and `new_var_labels3`. The new value labels objects should be named as `new_value_labels1`, `new_value_labels2`, and `new_value_labels3` **Hint: Use the `loc` and column names to filter. Update the dictionary.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "rec1_1 = rec_1.loc[ : , [\"CASEID\", \"V000\", \"V001\", \"V002\", \"V003\", \"V004\", \"V007\", \"V008\", \"V009\", \"V010\", \"V011\", \"V012\", \"V024\", \"V102\", \"V120\", \"V121\", \"V122\", \"V123\", \"V124\", \"V125\", \"V127\", \"V133\" ]]\n",
    "\n",
    "rec2_1 = rec_2.loc[ : , ['CASEID', 'V201', 'V218', 'V301', 'V302', 'V323', 'V323A', 'V325A', 'V326', 'V327', 'V337', 'V359', 'V360', 'V361', 'V362', 'V363', 'V364', 'V367', 'V372', 'V372A', 'V375A', 'V376', 'V376A', 'V379', 'V380']]\n",
    "\n",
    "rec3_1 = rec_3.loc[ : , ['CASEID', 'V501', 'V502', 'V503', 'V504', 'V505', 'V506', 'V507', 'V508', 'V509', 'V510', 'V511', 'V512', 'V513', 'V525', 'V613', 'V714', 'V715']]\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Generate a new column for `rec1_1` named as `year`. It should be equal to `2019`. Also, you must update this new variable for the `var_labels` dictionary. Generate a new key for `new_var_labels1` and the value for this key should be **\"Year of the survey\"** **Hint: Use `loc` and `update` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "rec1_1[\"year\"] = 2019\n",
    "\n",
    "var_labels1.update( {\"new_var_labels1\": \"Year of the survey\"} )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Merge `rec1_1`, `rec2_1`, and `rec3_1` using **CASEID**. Name this new object as `endes_2019`. **Hint: Use [this link](https://stackoverflow.com/questions/53645882/pandas-merging-101)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# First, we validate if CASEID it is unique within each data set\n",
    "(rec1_1['CASEID'].astype(str)).is_unique == (rec2_1['CASEID'].astype(str)).is_unique == (rec3_1['CASEID'].astype(str)).is_unique\n",
    "\n",
    "endes_2019 = rec1_1.merge( rec2_1, on =['CASEID'] , how = \"left\", validate = \"1:1\")\n",
    "endes_2019 = endes_2019.merge( rec3_1, on =['CASEID'] , how = \"left\", validate = \"1:1\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Unify all the `new_var_labels` in one object and `new_value_labels` in another one object. Name these two objects as `var_labels` and `value_labels`. Use them to generate new attributes for `endes_2019`. These attributes should be named as `var_labels` and `value_labels`. **Hint: Use `update` method.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "var_labels1.update(var_labels2)\n",
    "var_labels1.update(var_labels3)\n",
    "\n",
    "var_labels = var_labels1\n",
    "\n",
    "value_labels1.update(value_labels2)\n",
    "value_labels1.update(value_labels3)\n",
    "value_labels = value_labels1\n",
    "\n",
    "endes_2019.attrs['var_labels'] = var_labels\n",
    "endes_2019.attrs['value_labels'] = value_labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Get the min, max, sd, n_obs, n_missing for the following columns **total children ever born (V201)**, **Ideal number of children (V613)**, **Husbands education-single yrs (V715)**, and **Age at first marriage (V511)**. We want a dataframe with the following columns **Variables, Min, Max, Mean, N_obs, N_missing** and sort by the number of missing rows. **Hint: Use `describe` and `pivot` methods**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m endes_2019[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mV613\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m endes_2019[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mV613\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mastype( \u001B[38;5;28mfloat\u001B[39m )\n\u001B[0;32m      8\u001B[0m endes_2019[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mV715\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m endes_2019[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mV613\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mastype( \u001B[38;5;28mfloat\u001B[39m )\n\u001B[1;32m---> 10\u001B[0m endes_2019\u001B[38;5;241m.\u001B[39mV613\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;241m96\u001B[39m, \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnan\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     11\u001B[0m endes_2019\u001B[38;5;241m.\u001B[39mV715\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;241m98\u001B[39m, np\u001B[38;5;241m.\u001B[39mnan(), inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     13\u001B[0m endes_2019\u001B[38;5;241m.\u001B[39mloc[: , [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mV201\u001B[39m\u001B[38;5;124m'\u001B[39m , \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mV511\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mV613\u001B[39m\u001B[38;5;124m'\u001B[39m , \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mV715\u001B[39m\u001B[38;5;124m'\u001B[39m ]]\u001B[38;5;241m.\u001B[39mdescribe()\n",
      "\u001B[1;31mTypeError\u001B[0m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "# En la V613 hay strings \"Respuesta no numérica\" asociados al valor 96\n",
    "# En la V715 hay strings \"Respuesta no numérica\" asociados al valor 98\n",
    "\n",
    "endes_2019.V613.replace('Respuesta no numérica', 96, inplace=True)\n",
    "endes_2019.V715.replace('Respuesta no numérica', 98, inplace=True)\n",
    "\n",
    "endes_2019['V613'] = endes_2019['V613'].astype( float )\n",
    "endes_2019['V715'] = endes_2019['V613'].astype( float )\n",
    "\n",
    "endes_2019.V613.replace(96, np.nan(), inplace=True)\n",
    "endes_2019.V715.replace(98, np.nan(), inplace=True)\n",
    "\n",
    "endes_2019.loc[: , ['V201' , 'V511', 'V613' , 'V715' ]].describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Use `endes_2019` data to generate a new object named `mean_key_vars` to find the mean of **total children ever born (V201)**, **Ideal number of children (V613)**, **Husbands education-single yrs (V715)**, and **Age at first marriage (V511)** by year and department **(V024)**. Name these columns as **mean_total_children, mean_ideal_children, mean_hb_yr_educ and mean_first_marriage**, respectively. **Hint: Use groupby and [this link](https://stackoverflow.com/questions/40901770/is-there-a-simple-way-to-change-a-column-of-yes-no-to-1-0-in-a-pandas-dataframe).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\canun\\AppData\\Local\\Temp\\ipykernel_25152\\402326115.py:1: FutureWarning: The default value of numeric_only in DataFrameGroupBy.mean is deprecated. In a future version, numeric_only will default to False. Either specify numeric_only or select only columns which should be valid for the function.\n",
      "  mean_key_vars = endes_2019.loc[ : , ['V024' ,'year' , 'V201', 'V511' , 'V715' , 'V613']].groupby( [ 'V024' ,'year' ] ).mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": "                         V201       V511\nV024           year                     \n Huanuco       2019  1.989754  19.818632\n Ica           2019  1.671034  20.747208\n Junin         2019  1.836656  20.683761\n La Libertad   2019  1.704082  20.774678\n Lambayeque    2019  1.673928  20.953831\n Lima          2019  1.476121  21.946329\n Loreto        2019  2.157568  18.448529\n Madre de Dios 2019  1.972514  19.467449\n Moquegua      2019  1.626724  21.640046\n Pasco         2019  1.854436  20.395379\n Piura         2019  1.812752  20.451737\n Puno          2019  1.794307  20.398964\n San Martin    2019  1.903340  18.953155\n Tacna         2019  1.436502  22.065095\n Tumbes        2019  1.756925  19.409821\n Ucayali       2019  2.012258  18.985481\nAmazonas       2019  1.980892  19.266152\nAncash         2019  1.771065  20.591581\nApurimac       2019  2.003463  20.064982\nArequipa       2019  1.539910  22.304394\nAyacucho       2019  1.848787  20.340228\nCajamarca      2019  1.931559  19.610695\nCallao         2019  1.567164  21.517241\nCusco          2019  1.894415  20.283154\nHuancavelica   2019  2.083969  19.780769",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>V201</th>\n      <th>V511</th>\n    </tr>\n    <tr>\n      <th>V024</th>\n      <th>year</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Huanuco</th>\n      <th>2019</th>\n      <td>1.989754</td>\n      <td>19.818632</td>\n    </tr>\n    <tr>\n      <th>Ica</th>\n      <th>2019</th>\n      <td>1.671034</td>\n      <td>20.747208</td>\n    </tr>\n    <tr>\n      <th>Junin</th>\n      <th>2019</th>\n      <td>1.836656</td>\n      <td>20.683761</td>\n    </tr>\n    <tr>\n      <th>La Libertad</th>\n      <th>2019</th>\n      <td>1.704082</td>\n      <td>20.774678</td>\n    </tr>\n    <tr>\n      <th>Lambayeque</th>\n      <th>2019</th>\n      <td>1.673928</td>\n      <td>20.953831</td>\n    </tr>\n    <tr>\n      <th>Lima</th>\n      <th>2019</th>\n      <td>1.476121</td>\n      <td>21.946329</td>\n    </tr>\n    <tr>\n      <th>Loreto</th>\n      <th>2019</th>\n      <td>2.157568</td>\n      <td>18.448529</td>\n    </tr>\n    <tr>\n      <th>Madre de Dios</th>\n      <th>2019</th>\n      <td>1.972514</td>\n      <td>19.467449</td>\n    </tr>\n    <tr>\n      <th>Moquegua</th>\n      <th>2019</th>\n      <td>1.626724</td>\n      <td>21.640046</td>\n    </tr>\n    <tr>\n      <th>Pasco</th>\n      <th>2019</th>\n      <td>1.854436</td>\n      <td>20.395379</td>\n    </tr>\n    <tr>\n      <th>Piura</th>\n      <th>2019</th>\n      <td>1.812752</td>\n      <td>20.451737</td>\n    </tr>\n    <tr>\n      <th>Puno</th>\n      <th>2019</th>\n      <td>1.794307</td>\n      <td>20.398964</td>\n    </tr>\n    <tr>\n      <th>San Martin</th>\n      <th>2019</th>\n      <td>1.903340</td>\n      <td>18.953155</td>\n    </tr>\n    <tr>\n      <th>Tacna</th>\n      <th>2019</th>\n      <td>1.436502</td>\n      <td>22.065095</td>\n    </tr>\n    <tr>\n      <th>Tumbes</th>\n      <th>2019</th>\n      <td>1.756925</td>\n      <td>19.409821</td>\n    </tr>\n    <tr>\n      <th>Ucayali</th>\n      <th>2019</th>\n      <td>2.012258</td>\n      <td>18.985481</td>\n    </tr>\n    <tr>\n      <th>Amazonas</th>\n      <th>2019</th>\n      <td>1.980892</td>\n      <td>19.266152</td>\n    </tr>\n    <tr>\n      <th>Ancash</th>\n      <th>2019</th>\n      <td>1.771065</td>\n      <td>20.591581</td>\n    </tr>\n    <tr>\n      <th>Apurimac</th>\n      <th>2019</th>\n      <td>2.003463</td>\n      <td>20.064982</td>\n    </tr>\n    <tr>\n      <th>Arequipa</th>\n      <th>2019</th>\n      <td>1.539910</td>\n      <td>22.304394</td>\n    </tr>\n    <tr>\n      <th>Ayacucho</th>\n      <th>2019</th>\n      <td>1.848787</td>\n      <td>20.340228</td>\n    </tr>\n    <tr>\n      <th>Cajamarca</th>\n      <th>2019</th>\n      <td>1.931559</td>\n      <td>19.610695</td>\n    </tr>\n    <tr>\n      <th>Callao</th>\n      <th>2019</th>\n      <td>1.567164</td>\n      <td>21.517241</td>\n    </tr>\n    <tr>\n      <th>Cusco</th>\n      <th>2019</th>\n      <td>1.894415</td>\n      <td>20.283154</td>\n    </tr>\n    <tr>\n      <th>Huancavelica</th>\n      <th>2019</th>\n      <td>2.083969</td>\n      <td>19.780769</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_key_vars = endes_2019.loc[ : , ['V024' ,'year' , 'V201', 'V511' , 'V715' , 'V613']].groupby( [ 'V024' ,'year' ] ).mean()\n",
    "mean_key_vars"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Reshape `mean_key_vars` from wide to long. We want a dataframe with three columns **dpto, variables, values**. Name this object as `reshape_mean_key_vars`. **Hint: Use melt method**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Replicate your answers for questions 7 and 8, but in one line of code. Make it the most simple as possible. **NO HINT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Merge `reshape_mean_key_vars` with `endes_2019`. Name this object `final_result`. **Hint: Use merge.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
