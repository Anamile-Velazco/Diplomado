{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0hS_Z18eMAm"
      },
      "source": [
        "# Assigment 4\n",
        "\n",
        "This assigment will be graded if everything works well. I will run the script as once and everything should be done without errors and mistakes. I should be able to run your scripts in my computer and get all the results. **USE RELATIVE PATHS**. An error or exception or anything that breaks the code will means NO GRADE (0). Additionally, you are not able to modify any file handly. It also means NO GRADE (0). Comment everything you think will help others read your script. We expect 0 errors using GitHub. Everything will be graded!\n",
        "\n",
        "**ASK EVERYTHING! WE ARE HERE TO HELP YOU!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AowPVlXeMAv"
      },
      "source": [
        "In this path **..\\_data\\sbs\\B_RawData\\bancos** you will find scraped data from [this link](https://www.sbs.gob.pe/app/pp/EstadisticasSAEEPortal/Paginas/TIActivaTipoCreditoEmpresa.aspx?tip=B). We get all the information of the last available day of every each month.\n",
        "\n",
        "1. Import all the data and generate a column named as `date_info` that should have the day to information corresponds.\n",
        "2. Append all this datasets and generate a unique dataframe. This newdataset should have information at `rate interest` and `date` level. The columns should be the name of the banks. Be careful since not all the excel files have the same format. **It is totally prohibited to manipulate manually the excel files. This kind of action means NO GRADE on this project.**\n",
        "3. What are the top 5 banks each year with the highest interest rate at `Préstamos hipotecarios para vivienda`, `Consumo -\n",
        "Tarjetas de Crédito`. Present a dataframe with these variables: `year`, `rate_concept`, `banks`, `rate_value`.\n",
        "4. We want to save this dataset in the folder **_output/sbs/group_#**, but we want to save a file per bank. We want to have the information disaggregated at the bank level. Please, save your files with the name of the bank. Avoid blank spaces and use only lowercase letters. Generate the folder of your group using python code. **Hint: os library**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x79ZRvOep_hv"
      },
      "source": [
        "### SOLUTIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hmcP-W9p_hz"
      },
      "source": [
        "#### Part 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7jYvi9Cp_h0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wuOAXABp_h1"
      },
      "outputs": [],
      "source": [
        "# Set relative and full paths\n",
        "\n",
        "path = '../../_data/sbs/B_RawData/bancos/'\n",
        "fullpath = os.path.abspath('../../_data/sbs/B_RawData/bancos/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "__oiqKZKp_h1"
      },
      "outputs": [],
      "source": [
        "# Import excel files and add a column called \"date_info\", which takes information from the excel files names.\n",
        "\n",
        "dfs = []\n",
        "for file in os.listdir(path):\n",
        "    date_info = file[file.rindex('table_clean_')+12:]\n",
        "    date_info = date_info[:-5]\n",
        "    table_names_path = os.path.join(fullpath, f'{file}')\n",
        "    data = pd.read_excel(table_names_path)\n",
        "    data['date_info'] = date_info\n",
        "    dfs.append(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5by_oPo0p_h1"
      },
      "source": [
        "#### Part 2. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "odaWdQgrp_h2"
      },
      "outputs": [],
      "source": [
        "# Loop to homogenize the excel files\n",
        "\n",
        "for i, df in enumerate(dfs):\n",
        "    if dfs[i].shape[0] < 25:\n",
        "        dfs[i] = dfs[i].T\n",
        "        new_colnames = dfs[i].iloc[0]\n",
        "        dfs[i] = dfs[i][1:]\n",
        "        dfs[i].columns = new_colnames\n",
        "        dfs[i] = dfs[i].reset_index()\n",
        "        dfs[i].columns.values[0] = \"first_col\"\n",
        "        dfs[i].columns.values[1] = \"second_col\"\n",
        "        dfs[i].columns.values[2] = \"third_col\"\n",
        "        dfs[i].columns.values[-1] = \"last_col\"\n",
        "        dfs[i][dfs[i]['last_col'].isnull()]=dfs[i][dfs[i]['last_col'].isnull()].shift(axis=1)\n",
        "        dfs[i] = dfs[i].shift(-1, axis=1).dropna(axis=1)\n",
        "        dfs[i]['catamaran'] = dfs[i].iloc[:,-1:]\n",
        "        if dfs[i].shape[1] > 1: \n",
        "            dfs[i]['date_info'] = dfs[i]['catamaran'].iloc[len(dfs[i].index) - 1]\n",
        "            dfs[i]['Tasa Anual (%)'] = dfs[i]['first_col'] + dfs[i]['third_col']\n",
        "            dfs[i] = dfs[i].drop(['first_col', 'second_col', 'third_col', 'catamaran'], axis=1)\n",
        "            dfs[i] = dfs[i].iloc[:-1 , :]\n",
        "            dfs[i].index.names = ['index']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U0kSAbx3p_h2"
      },
      "outputs": [],
      "source": [
        "# Append vertically the excel files\n",
        "\n",
        "data = pd.concat(dfs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "2knwMBqDp_h2"
      },
      "outputs": [],
      "source": [
        "# Order columns\n",
        "\n",
        "data = data.reindex(columns =['Tasa Anual (%)', 'date_info', 'TRABAJO',\n",
        "                              'BBVA', 'BANCO DE COMERCIO', 'BANCO DE CREDITO',\n",
        "                              'BANCO PICHINCHA', 'BANBIF', 'STANDARD CHARTERED',\n",
        "                              'BANCO SUDAMERICANO', 'WIESE SUDAMERIS', 'BANK BOSTON',\n",
        "                              'BNP PARIBAS EL', 'CITIBANK DEL PERU','INTERBANK', \n",
        "                              'MIBANCO','SCOTIABANK PERU', 'HSBC', 'BANCO FALABELLA', \n",
        "                              'SANTANDER PERU','BANCO RIPLEY', 'ALFIN BANCO', \n",
        "                              'DEUTSCHE BANK PERU','Promedio del Sistema', 'Comercio', \n",
        "                              'Crédito', 'Pichincha', 'BIF','Scotiabank', 'Citibank', \n",
        "                              'Interbank', 'Mibanco', 'GNB', 'Falabella', 'Santander', \n",
        "                              'Ripley', 'Azteca', 'ICBC', 'Bank of China', 'Promedio',\n",
        "                              'Continental', 'Financiero', 'Banco GNB', 'Deutsche', \n",
        "                              'Cencosud', 'CAT', 'Alfin', 'B SANTANDER CENTRAL', 'Azteca  *',\n",
        "                              'HSBC(*)', 'Financiero  *', 'BCI'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdoLENd-p_h2"
      },
      "outputs": [],
      "source": [
        "data.to_excel('final_data.xlsx')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxWhMJ3Pp_h3"
      },
      "source": [
        "## Part 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "pXPEtRVRp_h3",
        "outputId": "27dc5d3a-f9ab-4f4e-fc47-26ce4ba59508"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Tasa Anual (%)</th>\n",
              "      <th>date_info</th>\n",
              "      <th>TRABAJO</th>\n",
              "      <th>BBVA</th>\n",
              "      <th>BANCO DE COMERCIO</th>\n",
              "      <th>BANCO DE CREDITO</th>\n",
              "      <th>BANCO PICHINCHA</th>\n",
              "      <th>BANBIF</th>\n",
              "      <th>STANDARD CHARTERED</th>\n",
              "      <th>...</th>\n",
              "      <th>Banco GNB</th>\n",
              "      <th>Deutsche</th>\n",
              "      <th>Cencosud</th>\n",
              "      <th>CAT</th>\n",
              "      <th>Alfin</th>\n",
              "      <th>B SANTANDER CENTRAL</th>\n",
              "      <th>Azteca  *</th>\n",
              "      <th>HSBC(*)</th>\n",
              "      <th>Financiero  *</th>\n",
              "      <th>BCI</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Avances en Cta.Corriente-</td>\n",
              "      <td>26_2_2004</td>\n",
              "      <td>38.92</td>\n",
              "      <td>-</td>\n",
              "      <td>73.34</td>\n",
              "      <td>-</td>\n",
              "      <td>39.08</td>\n",
              "      <td>-</td>\n",
              "      <td>31.73</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Sobregiros-</td>\n",
              "      <td>26_2_2004</td>\n",
              "      <td>48.79</td>\n",
              "      <td>138.18</td>\n",
              "      <td>89.00</td>\n",
              "      <td>-</td>\n",
              "      <td>68.30</td>\n",
              "      <td>25.00</td>\n",
              "      <td>58.10</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Dsctos. y préstamos hasta 30 días-</td>\n",
              "      <td>26_2_2004</td>\n",
              "      <td>8.19</td>\n",
              "      <td>47.46</td>\n",
              "      <td>4.62</td>\n",
              "      <td>15.87</td>\n",
              "      <td>14.43</td>\n",
              "      <td>-</td>\n",
              "      <td>30.68</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Dsctos. y préstamos 31 - 90 días-</td>\n",
              "      <td>26_2_2004</td>\n",
              "      <td>5.94</td>\n",
              "      <td>21.61</td>\n",
              "      <td>7.19</td>\n",
              "      <td>15.71</td>\n",
              "      <td>10.91</td>\n",
              "      <td>-</td>\n",
              "      <td>11.90</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Dsctos. y préstamos 91 - 180 días-</td>\n",
              "      <td>26_2_2004</td>\n",
              "      <td>10.00</td>\n",
              "      <td>19.71</td>\n",
              "      <td>5.34</td>\n",
              "      <td>15.82</td>\n",
              "      <td>10.71</td>\n",
              "      <td>-</td>\n",
              "      <td>9.98</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 53 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                      Tasa Anual (%)  date_info TRABAJO    BBVA  \\\n",
              "0           0           Avances en Cta.Corriente-  26_2_2004   38.92       -   \n",
              "1           1                         Sobregiros-  26_2_2004   48.79  138.18   \n",
              "2           2  Dsctos. y préstamos hasta 30 días-  26_2_2004    8.19   47.46   \n",
              "3           3   Dsctos. y préstamos 31 - 90 días-  26_2_2004    5.94   21.61   \n",
              "4           4  Dsctos. y préstamos 91 - 180 días-  26_2_2004   10.00   19.71   \n",
              "\n",
              "  BANCO DE COMERCIO BANCO DE CREDITO BANCO PICHINCHA BANBIF  \\\n",
              "0             73.34                -           39.08      -   \n",
              "1             89.00                -           68.30  25.00   \n",
              "2              4.62            15.87           14.43      -   \n",
              "3              7.19            15.71           10.91      -   \n",
              "4              5.34            15.82           10.71      -   \n",
              "\n",
              "  STANDARD CHARTERED  ... Banco GNB Deutsche Cencosud  CAT Alfin  \\\n",
              "0              31.73  ...       NaN      NaN      NaN  NaN   NaN   \n",
              "1              58.10  ...       NaN      NaN      NaN  NaN   NaN   \n",
              "2              30.68  ...       NaN      NaN      NaN  NaN   NaN   \n",
              "3              11.90  ...       NaN      NaN      NaN  NaN   NaN   \n",
              "4               9.98  ...       NaN      NaN      NaN  NaN   NaN   \n",
              "\n",
              "  B SANTANDER CENTRAL Azteca  * HSBC(*) Financiero  *  BCI  \n",
              "0                 NaN       NaN     NaN           NaN  NaN  \n",
              "1                 NaN       NaN     NaN           NaN  NaN  \n",
              "2                 NaN       NaN     NaN           NaN  NaN  \n",
              "3                 NaN       NaN     NaN           NaN  NaN  \n",
              "4                 NaN       NaN     NaN           NaN  NaN  \n",
              "\n",
              "[5 rows x 53 columns]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_excel(r'final_data.xlsx')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75_qAWz8p_h4"
      },
      "outputs": [],
      "source": [
        "#DEBEMOS PERCATARNOS que hay datos de múltiples años, será necesario ubicar el dato correspondiente a cada ano y luego generr el ranking para las tres variables requerida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQUMLgWmp_h4",
        "outputId": "c30957b5-172b-49c8-f985-2b32813493f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RangeIndex(start=0, stop=9154, step=1)\n"
          ]
        }
      ],
      "source": [
        "index = df.index\n",
        "print(index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEXxRa-Rp_h4",
        "outputId": "510e3610-22d9-42ed-946a-0f0a8ecebe65"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tasa Anual (%)</th>\n",
              "      <th>date_info</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Avances en Cta.Corriente-</td>\n",
              "      <td>26_2_2004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sobregiros-</td>\n",
              "      <td>26_2_2004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dsctos. y préstamos hasta 30 días-</td>\n",
              "      <td>26_2_2004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Dsctos. y préstamos 31 - 90 días-</td>\n",
              "      <td>26_2_2004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dsctos. y préstamos 91 - 180 días-</td>\n",
              "      <td>26_2_2004</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9149</th>\n",
              "      <td>Préstamos no Revolventes para libre disponibil...</td>\n",
              "      <td>31_8_2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9150</th>\n",
              "      <td>Préstamos no Revolventes para libre disponibil...</td>\n",
              "      <td>31_8_2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9151</th>\n",
              "      <td>Créditos pignoraticios</td>\n",
              "      <td>31_8_2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9152</th>\n",
              "      <td>Hipotecarios</td>\n",
              "      <td>31_8_2022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9153</th>\n",
              "      <td>Préstamos hipotecarios para vivienda</td>\n",
              "      <td>31_8_2022</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9154 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Tasa Anual (%)  date_info\n",
              "0                             Avances en Cta.Corriente-  26_2_2004\n",
              "1                                           Sobregiros-  26_2_2004\n",
              "2                    Dsctos. y préstamos hasta 30 días-  26_2_2004\n",
              "3                     Dsctos. y préstamos 31 - 90 días-  26_2_2004\n",
              "4                    Dsctos. y préstamos 91 - 180 días-  26_2_2004\n",
              "...                                                 ...        ...\n",
              "9149  Préstamos no Revolventes para libre disponibil...  31_8_2022\n",
              "9150  Préstamos no Revolventes para libre disponibil...  31_8_2022\n",
              "9151                             Créditos pignoraticios  31_8_2022\n",
              "9152                                       Hipotecarios  31_8_2022\n",
              "9153               Préstamos hipotecarios para vivienda  31_8_2022\n",
              "\n",
              "[9154 rows x 2 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.iloc[:,0:2]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.date_info.unique()\n",
        "#estos son todos los valores únicos en la columna date_info"
      ],
      "metadata": {
        "id": "uA1CNgNoqPf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#notemos que podemos filtrar la base por el valor de una observación en la columna date_info\n",
        "value='26_2_2004'\n",
        "dfa=df.query(\"date_info == @value\") "
      ],
      "metadata": {
        "id": "AbdQv-4hqdOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfa.head(3) #este dataframe solo cuenta con observaciones que son del 26/02/2004"
      ],
      "metadata": {
        "id": "fQl89Ke3qR2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array_date = df.date_info.unique() #guardamos todos los valores únicos de fecha en un objeto array\n",
        "dict1 = {} #generamos un diccionario vacío\n",
        "\n",
        "#para cada fecha única en el array_date generaremos un dataframe que, a su vez, estará almacenado en un diccionario llamato dict1\n",
        "for date in array_date:\n",
        "    dict1[f'df_{date}']=df.query(\"date_info == @date\") #condición para filtrar por date\n",
        "    print(date)\n",
        "    \n",
        "#Notemos que al array_date tiene una nan, hay que eliminarlo para que el código corra (lo haremos a continuación)"
      ],
      "metadata": {
        "id": "xpx2lZk_qoZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array_date  = array_date [~pd.isnull(array_date)] #eliminamos los nan en el array\n",
        "array_date "
      ],
      "metadata": {
        "id": "yKs-GgRXqrAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict1[\"df_26_2_2010\"].head() #de esta forma llamamos a un dataframe dentro del diccionario, especificando su date_info"
      ],
      "metadata": {
        "id": "Q-IYC8GIqtO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para cada dataframe del grupo dividido según fecha (en dict1) realizaremos el mismo procesamiento y generaremos un nuevo dataframe. Ahora bien, notemos que la fila de Préstamos hipotecarios para vivienda es la última en cada dataframe, que los nombres de esta fila son diferentes en cada frame, pero la posición es la misma, es decir, la última del dataframe. Aprovehcemos esto para el procesamiento"
      ],
      "metadata": {
        "id": "evp2qlSpqvmN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dict1[\"df_26_2_2010\"].iloc[-1,:], dict1[\"df_30_6_2022\"].iloc[-1,:], dict1[\"df_31_5_2007\"].iloc[-1,:]) \n",
        "#ejemplo de que la información de créditos hipotecarios se encuentra en la última fila de dos dataframe relativos al 26 de febrero de 2010 y al 30 de junio de 2022"
      ],
      "metadata": {
        "id": "UOqvYQVqqvQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(dict1[\"df_26_2_2010\"].iloc[-1,:]) #esta información está almacenada en forma de serie"
      ],
      "metadata": {
        "id": "re_QH0QwqvTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7_NI0Amp_h4",
        "outputId": "ed5b4040-0f2e-45ff-dd50-8bcb19a0ce19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array_date = df.date_info.unique() #guardamos todos los valores únicos de fecha en un objeto array\n",
        "array_date  = array_date [~pd.isnull(array_date)] #eliminamos los NaN\n",
        "dict1 = {} #generamos un diccionario vacío para guardar las series que contienen información del crédito hipotecario (según banco), una por cada fecha\n",
        "df3 = pd.DataFrame() #generamos un dataframe vacío para guardar la información de cada fecha\n",
        "\n",
        "for date in array_date:\n",
        "    dict1[f'df_{date}']=df.query(\"date_info == @date\") #condición para filtrar por date (el nombre de cada dataframe será: df_fecha)\n",
        "    serie_row= dict1[f'df_{date}'].iloc[-1,:] #guardamos el resultado de la información de crédito hipotecario en una serie\n",
        "    df3[f'CH_{date}'] = serie_row.to_frame() #convertimos las series en un dataframe, cada serie representará una columna de df3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = df3.drop(df3.index[0:2]).reset_index()  #eliminamos las dos primeras filas del objeto y generamos un nuevo índice\n",
        "df3 = df3.rename(columns = {'index':'Nombre del banco'}) #renombramos la columna con información de nombre de bancos\n",
        "df3.head()"
      ],
      "metadata": {
        "id": "_k8Q3QJzrJuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reemplazamos la información que es texto con valores nulos y convertimos los missings en valores nulos\n",
        "df3 = df3.replace(['-','s.i.'], 0).fillna(0) "
      ],
      "metadata": {
        "id": "QcLvtJJgrJ2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.iloc[:,1:] = df3.iloc[:,1:].astype(float)  #convertimos las columnas con información de tasas a formato float\n",
        "df3.head(3)"
      ],
      "metadata": {
        "id": "RqY0mqnSsx5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3.dtypes #confirmamos que el proceso fue exitoso"
      ],
      "metadata": {
        "id": "Dg7_w1S-rJ5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_top5 = df3.iloc[:,0:2].nlargest(5, ['CH_26_2_2004']) #de esta forma identificamos a los bancos con las tasas de interés de crédito hipotecario más altas en la fecha indicada por el nombre de la columna\n",
        "df_top5"
      ],
      "metadata": {
        "id": "FKLFSEUMrJ8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_top5 = df3.iloc[:,0:2].nlargest(5, ['CH_26_2_2004']) #de esta forma identificamos a los bancos con las tasas de interés de crédito hipotecario más altas en la fecha indicada por el nombre de la columna\n",
        "df_top5"
      ],
      "metadata": {
        "id": "RYWZQKRUrAxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pero el ejercicio requiere cambiar la denominación de las columnas e incluir el año y concepto de tasa de interés\n",
        "df_top5.rename(columns = {'Nombre del banco':'banks', 'CH_26_2_2004':'rate_value'}, inplace = True)\n",
        "df_top5['year']= 2004\n",
        "df_top5['rate_concept']= 'Crédito Hipotecario'\n",
        "df_top5"
      ],
      "metadata": {
        "id": "cwyu2n3RrTZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos generar un loop para obtener la información del resto de fechas replicando el proceso previo (ahora para cada fecha)"
      ],
      "metadata": {
        "id": "qqMRhhiprZ4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3.loc[:,['Nombre del banco','CH_26_2_2004']].head(3) #así extraemos la columna de nombre de banco y una columna dada de fecha\n",
        "#esto será necesario al momento de generar el loop"
      ],
      "metadata": {
        "id": "hxMEIxnNrTbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict3 = {} #generamos un diccionario vacío\n",
        "\n",
        "#replicamos el códgio previo empleando un iterador que corra a través del array de fechas\n",
        "for date in array_date:\n",
        "    dict3[f'df_top5_{date}']=df3.loc[:,['Nombre del banco',f'CH_{date}']].nlargest(5, [f'CH_{date}']) \n",
        "    dict3[f'df_top5_{date}']['year'] = f'{date}'\n",
        "    dict3[f'df_top5_{date}']['rate_concept'] = 'Crédito Hipotecario' \n",
        "    #llenamos el didcionario de dataframes que contengan solo el nombre, la fecha, el concepto de tasa y la tasa de interés de los cinco bancos con mayor tasa de interés por fecha"
      ],
      "metadata": {
        "id": "ZCQb2nwarTeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#por ejemplo:\n",
        "dict3['df_top5_30_6_2021']"
      ],
      "metadata": {
        "id": "6PtboQM9rThG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict3['df_top5_30_6_2021'].append(dict3['df_top5_26_2_2004'], ignore_index=True)\n",
        "#Notemos que dado que los nombres de las columnas de valores no coinciden, no podemos integrar verticalmente la información sin generar NaN"
      ],
      "metadata": {
        "id": "V89ipMGRrfJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generamos un dataframe vacío\n",
        "dfx = pd.DataFrame()\n",
        "\n",
        "for date in array_date:\n",
        "    dict3[f'df_top5_{date}'].rename(columns = {f'CH_{date}':'rate_value'}, inplace = True)\n",
        "    #La línea anterior cambia el nombre de todas las columnas, de forma que podamos integrarlas verticalmente\n",
        "    dfx = dfx.append(dict3[f'df_top5_{date}'])"
      ],
      "metadata": {
        "id": "vlO4w98YrfMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfx"
      ],
      "metadata": {
        "id": "OLxtokpTrfPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfx.rename(columns = {'Nombre del banco':'banks'}, inplace = True) #cambiamos el nombre de la columna de información de bancos\n",
        "dfx['year'] = dfx['year'].str[-4:] #nos quedamos con el año de la fecha (en formato string)\n",
        "dfx.reset_index(inplace=True) #generamos un nuevo índice \n",
        "dfx.drop(['index'],axis=1,inplace=True) #quitamos el índice\n",
        "dfx"
      ],
      "metadata": {
        "id": "Bw_G4q4irfRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El código para las tasas de interés de consumo y tarjeta de crédito es similar al desarrollado previamente, como veremos a continuación."
      ],
      "metadata": {
        "id": "MQ5A10Rjrm9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict1[\"df_31_10_2007\"].iloc[7]\n",
        "#no obstante, hay una distinción importante. En el caso de esta caategoría, mantiene distintas posiciones en las bases generadas"
      ],
      "metadata": {
        "id": "7yUqO1KcrfUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict1[\"df_30_11_2016\"]\n",
        "#como se muestra aquí"
      ],
      "metadata": {
        "id": "vMoaSQW4rfW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#será necesario establecer una condición para extraer solo las filas relativas a la tasa de interés de tarjetas de crédito\n",
        "df = pd.DataFrame()\n",
        "df['sub_string'] = dict1[\"df_31_10_2007\"]['Tasa Anual (%)'].str[0:2] #así podemos extraer las primeras letras de los strings de las filas en el dataframe"
      ],
      "metadata": {
        "id": "tw4l1wvZrTjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head() #el resultado"
      ],
      "metadata": {
        "id": "bTPDFelnrTmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= dict1[\"df_31_10_2007\"] # y de esta forma podemos filtrar por todas las filas que contengan la palabra tarjeta\n",
        "df[df['Tasa Anual (%)'].str.contains('Tarjeta')].iloc[0]"
      ],
      "metadata": {
        "id": "bVtWp2__rvJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(r'E:\\UNIVERSIDADES\\DIPLOMATURA_QLAB\\Fundamentos_Python\\Data\\final_data.xlsx')\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "72B2EDT2rvL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict4 = {} #generamos un diccionario vacío para guardar las series que contienen información del crédito hipotecario (según banco), una por cada fecha\n",
        "df4 = pd.DataFrame() \n",
        "\n",
        "for date in array_date:\n",
        "    dict4[f'df_{date}']=df.query(\"date_info == @date\") #condición para filtrar por date (el nombre de cada dataframe será: df_fecha)\n",
        "    serie_row= dict4[f'df_{date}'][dict4[f'df_{date}']['Tasa Anual (%)'].str.contains('Tarjeta')].iloc[0] #guardamos el resultado de la información de crédito hipotecario en una serie\n",
        "    df4[f'CH_{date}'] = serie_row.to_frame() #convertimos las series en un dataframe, cada serie representará una columna de df3"
      ],
      "metadata": {
        "id": "V5sNQbESrvOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4.head(2)"
      ],
      "metadata": {
        "id": "DpK5fhOrrvRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = df4.drop(df4.index[0:2]).reset_index()  #eliminamos las dos primeras filas del objeto y generamos un nuevo índice\n",
        "df4 = df4.rename(columns = {'index':'Nombre del banco'}) #renombramos la columna con información de nombre de bancos\n",
        "df4.head()"
      ],
      "metadata": {
        "id": "5R-sHUZIr3TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = df4.replace(['-','s.i.'], 0).fillna(0) #cambiamos las observaciones strings y NaN"
      ],
      "metadata": {
        "id": "0K3gv89Rr3Vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4.iloc[:,1:] = df4.iloc[:,1:].astype(float)  #convertimos las columnas con información de tasas a formato float\n",
        "df4.head(3)"
      ],
      "metadata": {
        "id": "vnznBiE9r3Xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict5 = {} #generamos un diccionario vacío\n",
        "\n",
        "#replicamos el códgio previo empleando un iterador que corra a través del array de fechas\n",
        "for date in array_date:\n",
        "    dict5[f'df_top5_{date}']=df4.loc[:,['Nombre del banco',f'CH_{date}']].nlargest(5, [f'CH_{date}']) \n",
        "    dict5[f'df_top5_{date}']['year'] = f'{date}'\n",
        "    dict5[f'df_top5_{date}']['rate_concept'] = 'Tarjeta de crédito' \n",
        "    #llenamos el didcionario de dataframes que contengan solo el nombre, la fecha, el concepto de tasa y la tasa de interés de los cinco bancos con mayor tasa de interés por fecha"
      ],
      "metadata": {
        "id": "dnGEbtORr3Zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfy = pd.DataFrame()\n",
        "\n",
        "for date in array_date:\n",
        "    dict5[f'df_top5_{date}'].rename(columns = {f'CH_{date}':'rate_value'}, inplace = True)\n",
        "    #La línea anterior cambia el nombre de todas las columnas, de forma que podamos integrarlas verticalmente\n",
        "    dfy = dfy.append(dict5[f'df_top5_{date}'])"
      ],
      "metadata": {
        "id": "UsIsNdBlr9_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfy.rename(columns = {'Nombre del banco':'banks'}, inplace = True) #cambiamos el nombre de la columna de información de bancos\n",
        "dfy['year'] = dfy['year'].str[-4:] #nos quedamos con el año de la fecha (en formato string)\n",
        "dfy.reset_index(inplace=True) #generamos un nuevo índice \n",
        "dfy.drop(['index'],axis=1,inplace=True) #quitamos el índice\n",
        "dfy"
      ],
      "metadata": {
        "id": "STF0maJtr-CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por último, integramos verticalmente ambos dataframes"
      ],
      "metadata": {
        "id": "HqkmpGpPsDZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dfz = dfx.append(dfy, ignore_index=True) #aplicamos append a a ambas bases\n",
        "dfz"
      ],
      "metadata": {
        "id": "_jJRqRFRr-IK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OMh3uWYp_h6"
      },
      "source": [
        "## Part 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIXMUuJOp_h6"
      },
      "outputs": [],
      "source": [
        "df.rename(columns = {'Tasa Anual (%)':'tasa_anual_percentage', \n",
        "                     'Azteca  *':'Azteca',\n",
        "                     'HSBC(*)':'HSBC',\n",
        "                     'Financiero  *':'Financiero'}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGSpYHQep_h6"
      },
      "outputs": [],
      "source": [
        "# Quitar espacios y letras mayúsculas de los nombres de las columnas\n",
        "df.columns = df.columns.str.replace(' ', '_')\n",
        "df.columns = df.columns.str.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [],
        "id": "NsxmSIrBp_h7"
      },
      "outputs": [],
      "source": [
        "# Crear bases por cada uno de los bancos\n",
        "not_requiered_columns = ['tasa_anual_percentage', 'date_info', 'trabajo']\n",
        "bases = []\n",
        "for col in df.columns.values:\n",
        "    if col not in not_requiered_columns:\n",
        "        data = df[['tasa_anual_percentage', 'date_info', col]]\n",
        "        bases.append(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyq5yldgp_h7"
      },
      "outputs": [],
      "source": [
        "# Crear el nuevo folder en la direccion especificada\n",
        "import os\n",
        "\n",
        "new_path = '../../_output/sbs/group7'\n",
        "if not os.path.exists( new_path ):\n",
        "   os.makedirs( new_path )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhScuIIKp_h7"
      },
      "outputs": [],
      "source": [
        "# Exportar las bases al path indicado\n",
        "for base in bases:\n",
        "    cols_names = [col for col in base if col not in not_requiered_columns]\n",
        "    for col in cols_names:\n",
        "        new_table_names_path = os.path.join(new_path, f'{col}.xlsx')\n",
        "        base.to_excel(new_table_names_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}