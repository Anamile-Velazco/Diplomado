{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assigment 4\n",
    "\n",
    "This assigment will be graded if everything works well. I will run the script as once and everything should be done without errors and mistakes. I should be able to run your scripts in my computer and get all the results. **USE RELATIVE PATHS**. An error or exception or anything that breaks the code will means NO GRADE (0). Additionally, you are not able to modify any file handly. It also means NO GRADE (0). Comment everything you think will help others read your script. We expect 0 errors using GitHub. Everything will be graded!\n",
    "\n",
    "**ASK EVERYTHING! WE ARE HERE TO HELP YOU!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this path **..\\_data\\sbs\\B_RawData\\bancos** you will find scraped data from [this link](https://www.sbs.gob.pe/app/pp/EstadisticasSAEEPortal/Paginas/TIActivaTipoCreditoEmpresa.aspx?tip=B). We get all the information of the last available day of every each month.\n",
    "\n",
    "1. Import all the data and generate a column named as `date_info` that should have the day to information corresponds.\n",
    "2. Append all this datasets and generate a unique dataframe. This newdataset should have information at `rate interest` and `date` level. The columns should be the name of the banks. Be careful since not all the excel files have the same format. **It is totally prohibited to manipulate manually the excel files. This kind of action means NO GRADE on this project.**\n",
    "3. What are the top 5 banks each year with the highest interest rate at `Préstamos hipotecarios para vivienda`, `Consumo -\n",
    "Tarjetas de Crédito`. Present a dataframe with these variables: `year`, `rate_concept`, `banks`, `rate_value`.\n",
    "4. We want to save this dataset in the folder **_output/sbs/group_#**, but we want to save a file per bank. We want to have the information disaggregated at the bank level. Please, save your files with the name of the bank. Avoid blank spaces and use only lowercase letters. Generate the folder of your group using python code. **Hint: os library**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solución pregunta 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerías\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuramos path del directorio \n",
    "os.chdir(\"C:\\\\Users\\\\User\\\\Documents\\\\GitHub\\\\Diplomado_PUCP\\\\Lecture_4\\\\Assigment_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observamos que la data tiene un primer formato desde enero 2002 hasta agosto 2010 y luego cambia\n",
    "# Definimos diccionarios que almacenen las bases importadas según formato de presentación de datos\n",
    "d_1 = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero se trabaja en las bases entre enero 2002 y agosto 2010\n",
    "# Se crea un loop que almacene cada dataframe en un diccionario\n",
    "# Luego, se agrega variable \"data_info\" a cada elemento del diccionario\n",
    "for day in range(26, 32):\n",
    "    for mes in range(1, 13):\n",
    "        for anio in range (2002, 2011):\n",
    "            if (anio != 2010 | (anio ==2010 & mes < 9)):\n",
    "                try:\n",
    "                    d_1[f\"bd_{day}_{mes}_{anio}\"] = pd.read_excel(fr\"../../_data/sbs/B_RawData/bancos/table_clean_{day}_{mes}_{anio}.xlsx\", header=[2])\n",
    "                    d_1[f\"bd_{day}_{mes}_{anio}\"][\"data_info\"] = (f\"{day}_{mes}_{anio}\")\n",
    "                except FileNotFoundError: \n",
    "                    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora se trabaja con el formato de las otras bases\n",
    "# [FALTA otras bases] "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solución pregunta 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se hace el append de los dataframes que componen los diccionarios\n",
    "bd1 = pd.concat(d_1.values(), ignore_index=True)\n",
    "\n",
    "#[FALTA para otras bases]\n",
    "#[FALTA hacer reshape en bd1 para que los bancos sean columnas]\n",
    "#[FALTA quedarse solo con variables tasa de interés en hipotecas]\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
